{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Wrangling Text Data in Python\n",
    "\n",
    "Same thing, but now only with codeblocks and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a file as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      "Class Goal\n",
      "The goal of this class is to make the skills of data wrangling in Python familiar and easy to use.\n",
      "2 Class Description\n",
      "This course covers data selection, cleaning, and manipulation in Python, in- cluding reading and writing data, the Pandas library for cleaning, transforming, merging, reshaping, and data aggregation. This course will make use of Collab for handling assignments and grading. We will also use GitHub for some code management (making an account is advised but not required). This course is worth 1 credit.\n",
      "3 Readings\n",
      "There is one book for this course, Python for Data Analysis. It is published by O’Reilly Media. You can read it free online via the UVa library (the link is on the Collab page). Readings will be assigned to supplement the in class portion of the class.\n",
      "1\n",
      "4 Assessment\n",
      "Grades will be assigned based on performance on 4 homework assignments each worth 100 points. The total of all points earned will be compared with the table below to determine the final\n"
     ]
    }
   ],
   "source": [
    "filename = 'example.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    raw_text = file_in.read()\n",
    "\n",
    "print(raw_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installing nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "$ pip3 install nltk\n",
    "$ python3\n",
    ">>> import nltk\n",
    ">>> nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## reading a file as lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 1\\n',\n",
       " 'Class Goal\\n',\n",
       " 'The goal of this class is to make the skills of data wrangling in Python familiar and easy to use.\\n',\n",
       " '2 Class Description\\n',\n",
       " 'This course covers data selection, cleaning, and manipulation in Python, in- cluding reading and writing data, the Pandas library for cleaning, transforming, merging, reshaping, and data aggregation. This course will make use of Collab for handling assignments and grading. We will also use GitHub for some code management (making an account is advised but not required). This course is worth 1 credit.\\n',\n",
       " '3 Readings\\n',\n",
       " 'There is one book for this course, Python for Data Analysis. It is published by O’Reilly Media. You can read it free online via the UVa library (the link is on the Collab page). Readings will be assigned to supplement the in class portion of the class.\\n',\n",
       " '1\\n',\n",
       " '4 Assessment\\n',\n",
       " 'Grades will be assigned based on performance on 4 homework assignments each worth 100 points. The total of all points earned will be compared with the table below to determine the final grade. Homework assignments will be released according to the schedule below and be due approximately one week later (there\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'example.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    raw_text = file_in.readlines()\n",
    "\n",
    "raw_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## problems with reading by \"lines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This course covers data selection, cleaning, and manipulation in Python, in- cluding reading and writing data, the Pandas library for cleaning, transforming, merging, reshaping, and data aggregation. This course will make use of Collab for handling assignments and grading. We will also use GitHub for some code management (making an account is advised but not required). This course is worth 1 credit.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# segmenting with nltk.sent_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 1\\nClass Goal\\nThe goal of this class is to make the skills of data wrangling in Python familiar and easy to use.',\n",
       " '2 Class Description\\nThis course covers data selection, cleaning, and manipulation in Python, in- cluding reading and writing data, the Pandas library for cleaning, transforming, merging, reshaping, and data aggregation.',\n",
       " 'This course will make use of Collab for handling assignments and grading.',\n",
       " 'We will also use GitHub for some code management (making an account is advised but not required).',\n",
       " 'This course is worth 1 credit.',\n",
       " '3 Readings\\nThere is one book for this course, Python for Data Analysis.',\n",
       " 'It is published by O’Reilly Media.',\n",
       " 'You can read it free online via the UVa library (the link is on the Collab page).',\n",
       " 'Readings will be assigned to supplement the in class portion of the class.',\n",
       " '1\\n4 Assessment\\nGrades will be assigned based on performance on 4 homework assignments each worth 100 points.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "filename = 'example.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    raw_text = file_in.read()\n",
    "\n",
    "sentences = nltk.sent_tokenize(raw_text)\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## can we even tell what a sentence is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Mrs. Rachael, I needn’t inform you who were acquainted with the late Miss Barbary’s affairs, that her means die with her and that this young lady, now her aunt is dead–”\n",
    "\n",
    "> “My aunt, sir!”\n",
    "\n",
    "> “It is really of no use carrying on a deception when no object is to be gained by it,” said Mr. Kenge smoothly, “Aunt in fact, though not in law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## mixing the approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 1',\n",
       " 'Class Goal',\n",
       " 'The goal of this class is to make the skills of data wrangling in Python familiar and easy to use.',\n",
       " '2 Class Description',\n",
       " 'This course covers data selection, cleaning, and manipulation in Python, in- cluding reading and writing data, the Pandas library for cleaning, transforming, merging, reshaping, and data aggregation.',\n",
       " 'This course will make use of Collab for handling assignments and grading.',\n",
       " 'We will also use GitHub for some code management (making an account is advised but not required).',\n",
       " 'This course is worth 1 credit.',\n",
       " '3 Readings',\n",
       " 'There is one book for this course, Python for Data Analysis.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "filename = 'example.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    raw_lines = file_in.readlines()\n",
    "\n",
    "sents = []\n",
    "for line in raw_lines:\n",
    "    sents.extend(nltk.sent_tokenize(line))\n",
    "\n",
    "sents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## core structure - the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1', 'Class', 'Goal', 'The', 'goal', 'of', 'this', 'class', 'is', 'to']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw_text)\n",
    "print(len(tokens))\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## difficulties with tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in-', 'cluding']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[40:42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## token vs type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 'Class', 'Goal', 'The', 'goal']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448\n",
      "222\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "unique_tokens = set(tokens)\n",
    "print(len(unique_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448\n",
      "222\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(set(tokens)))\n",
    "tokens = [token.lower() for token in tokens]\n",
    "print(len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## natural language processing pipeline two examples\n",
    "\n",
    "First example (word2vec - cares about sentence structure and ordering)\n",
    "* get text\n",
    "* segment text\n",
    "* tokenize texts, but preserve the sentences\n",
    "* lowercase all tokens\n",
    "* remove punctuation and stopwords\n",
    "* analyze\n",
    "\n",
    "Second example (stylometry - cares about punctuation and part of speech use)\n",
    "* get text\n",
    "* tokenize text (don't care about sentences)\n",
    "* lowercase all tokens\n",
    "* tag all words with parts of speech\n",
    "* analyze\n",
    "\n",
    "Third example (topic modeling with bag of words)\n",
    "* get text\n",
    "* divide each text into a hundred pieces\n",
    "* tokenize text\n",
    "* throw away the token ordering\n",
    "* analyze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
