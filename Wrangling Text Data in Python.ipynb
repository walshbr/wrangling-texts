{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Text Data in Python\n",
    "\n",
    "Jeremy\n",
    "\n",
    "There's a world of text out there - more than you could ever want to work through. Odds are pretty good that if you have a dream for analyzing a certain type of thing there is a text corpus out there for you. It might involve a lot of work to put that corpus together, but it is within your grasp once you get working.\n",
    "\n",
    "Gathering the data is just part of the problem though. Text data is messy. Really messy. And computers don't do so well with mess. A lot of the work of working with text data is trying to clean it up and structure it in some way that the computer knows how to handle it. I'll go through a few. Here we have a text document - example.txt - that we'll load in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      "Class Goal\n",
      "The goal of this class is to make the skills of data wrangling in Python familiar and easy to use.\n",
      "2 Class Description\n",
      "This course covers data selection, cleaning, and manipulation in Python, in- cluding reading and writing data, the Pandas library for cleaning, transforming, merging, reshaping, and data aggregation. This course will make use of Collab for handling assignments and grading. We will also use GitHub for some code management (making an account is advised but not required). This course is worth 1 credit.\n",
      "3 Readings\n",
      "There is one book for this course, Python for Data Analysis. It is published by Oâ€™Reilly Media. You can read it free online via the UVa library (the link is on the Collab page). Readings will be assigned to supplement the in class portion of the class.\n",
      "1\n",
      "4 Assessment\n",
      "Grades will be assigned based on performance on 4 homework assignments each worth 100 points. The total of all points earned will be compared with the table below to determine the final\n"
     ]
    }
   ],
   "source": [
    "filename = 'example.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    raw_text = file_in.read()\n",
    "\n",
    "print(raw_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the syllabus for the course. Looks pretty close to the real thing right? But our first clue that this data is unstructured is the 0:1000 bit at the end there. We're printing out the first 1000 characters. When we say unstructured, what we mean is that the computer has no sense of the underlying format, meaning, or structural elements of the text. It's just looking at it as a big long string, a sequence of characters thrown together. We have to do a lot of work to process the text and get it ready for working with in any program. This usually involves a few choices:\n",
    "\n",
    "* structuring\n",
    "* tagging\n",
    "\n",
    "I'll talk about the first two. Let's start with structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reverse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c3fc7ec60ccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reverse' is not defined"
     ]
    }
   ],
   "source": [
    "reverse(raw_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data that isn't structured at all;\n",
    "\n",
    "Data that's too structured; - TEI\n",
    "\n",
    "\n",
    "Take a chunk of text - it's unhelpful as a large string. You have to get the computer to think about it as discrete units. And the difficulty is that what we mean by discrete units when it comes to text is pretty complicated.\n",
    "\n",
    "There are lots of tools out there that can help. We'll be talking about NLTK a bit. \n",
    "\n",
    "Most basic form is  text file to words, or tokens. Example\n",
    "\n",
    "But we might also be interested in the actual structure of a file. Other options.\n",
    "\n",
    "Text file to lines - useful in some cases, particularly in poetry.\n",
    "\n",
    "But a \"line\" as a typographic concept is not something necessarily available to a computer. Often a paragraph that looks like several lines to us is actually input as one really long line before it gets to a paragraph break. So a single line might cross several sentences.\n",
    "\n",
    "Breaking at paragraphs. - need to know your corpus so that you know what the markers are that you can grab onto. How can you break a longer thing into units? You need signposts.\n",
    "\n",
    "Breaking larger texts into chunks.\n",
    "\n",
    "Token vs type.\n",
    "\n",
    "Punctuation and stopwords.\n",
    "\n",
    "Filtering for each.\n",
    "\n",
    "You're preprocessing for particular analysis.\n",
    "\n",
    "\n",
    "Hand wave at the natural language processing pipeline - this is all just one part of preprocessing a text before you're ready to work with it. And it largely entails knowing what the outcomes will be. I.e. - if you're interested in knowing the parts of speech associated with a particular text, you have to actually mark a text up as such or get access to something that can. So you might add parts to the NLP pipeline accordingly. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
